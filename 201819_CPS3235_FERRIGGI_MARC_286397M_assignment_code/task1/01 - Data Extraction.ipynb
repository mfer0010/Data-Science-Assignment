{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import pandas as pd\n",
    "from lxml import etree #for XML manipulation\n",
    "import py2neo as neo\n",
    "import re\n",
    "from py2neo import Graph, Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to xml file as its saved outside my git repo:\n",
    "path = '../../../DataFiles/dblp.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns (yields) a generator, so when the function is called,\n",
    "#it is not run. This is so that we don't have to store the data in memory, we\n",
    "#can simply work with it and discard it\n",
    "def iterate_xml(path):\n",
    "    doc = etree.iterparse(path,events=('start','end'),dtd_validation=True)\n",
    "    _, root = next(doc)\n",
    "    start_tag = None\n",
    "    for event, element in doc:\n",
    "        if event == 'start' and start_tag is None:\n",
    "            start_tag = element.tag\n",
    "        if event == 'end' and element.tag == start_tag:\n",
    "            yield element\n",
    "            start_tag = None\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to neo4j server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note, server must be running on localhost \n",
    "#sudo service neo4j start\n",
    "graph = Graph('bolt://localhost:7687', auth=('neo4j','ItIsABadIdeaToHardCodePasswords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY NEED TO RUN ONCE\n",
    "#Set Uniqueness Constraints on Nodes\n",
    "graph.schema.create_uniqueness_constraint('Article', 'key')\n",
    "graph.schema.create_uniqueness_constraint('Author', 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create headers on csv files\n",
    "with open('./data/articles.csv','w') as file:\n",
    "    line = 'key,title\\n'\n",
    "    file.write(line)\n",
    "\n",
    "with open('./data/authors.csv','w') as file:\n",
    "    line = 'name,university\\n'\n",
    "    file.write(line)\n",
    "\n",
    "with open('./data/published.csv','w') as file:\n",
    "    line = 'name,key\\n'\n",
    "    file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: 1.487326490970441%\n",
      "Extracting: 2.974652981940882%\n",
      "Extracting: 4.461979472911323%\n",
      "Extracting: 5.949305963881764%\n",
      "Extracting: 7.436632454852204%\n",
      "Extracting: 8.923958945822646%\n",
      "Extracting: 10.411285436793086%\n",
      "Extracting: 11.898611927763527%\n",
      "Extracting: 13.38593841873397%\n",
      "Extracting: 14.873264909704409%\n",
      "Extracting: 16.36059140067485%\n",
      "Extracting: 17.84791789164529%\n",
      "Extracting: 19.33524438261573%\n",
      "Extracting: 20.822570873586173%\n",
      "Extracting: 22.309897364556612%\n",
      "Extracting: 23.797223855527054%\n",
      "Extracting: 25.284550346497497%\n",
      "Extracting: 26.77187683746794%\n",
      "Extracting: 28.259203328438375%\n",
      "Extracting: 29.746529819408817%\n",
      "Extracting: 31.23385631037926%\n",
      "Extracting: 32.7211828013497%\n",
      "Extracting: 34.208509292320144%\n",
      "Extracting: 35.69583578329058%\n",
      "Extracting: 37.18316227426102%\n",
      "Extracting: 38.67048876523146%\n",
      "Extracting: 40.15781525620191%\n",
      "Extracting: 41.645141747172346%\n",
      "Extracting: 43.132468238142785%\n",
      "Extracting: 44.619794729113224%\n",
      "Extracting: 46.10712122008367%\n",
      "Extracting: 47.59444771105411%\n",
      "Extracting: 49.081774202024555%\n",
      "Extracting: 50.56910069299499%\n",
      "Extracting: 52.05642718396544%\n",
      "Extracting: 53.54375367493588%\n",
      "Extracting: 55.03108016590631%\n",
      "Extracting: 56.51840665687675%\n",
      "Extracting: 58.005733147847195%\n",
      "Extracting: 59.493059638817634%\n",
      "Extracting: 60.98038612978808%\n",
      "Extracting: 62.46771262075852%\n",
      "Extracting: 63.955039111728965%\n",
      "Extracting: 65.4423656026994%\n",
      "Extracting: 66.92969209366984%\n",
      "Extracting: 68.41701858464029%\n",
      "Extracting: 69.90434507561072%\n",
      "Extracting: 71.39167156658117%\n",
      "Extracting: 72.8789980575516%\n",
      "Extracting: 74.36632454852204%\n",
      "Extracting: 75.85365103949249%\n",
      "Extracting: 77.34097753046292%\n",
      "Extracting: 78.82830402143337%\n",
      "Extracting: 80.31563051240381%\n",
      "Extracting: 81.80295700337426%\n",
      "Extracting: 83.29028349434469%\n",
      "Extracting: 84.77760998531514%\n",
      "Extracting: 86.26493647628557%\n",
      "Extracting: 87.75226296725602%\n",
      "Extracting: 89.23958945822645%\n",
      "Extracting: 90.7269159491969%\n",
      "Extracting: 92.21424244016734%\n",
      "Extracting: 93.70156893113779%\n",
      "Extracting: 95.18889542210822%\n",
      "Extracting: 96.67622191307866%\n",
      "Extracting: 98.16354840404911%\n"
     ]
    }
   ],
   "source": [
    "#reset generator\n",
    "generator = iterate_xml(path)\n",
    "\n",
    "#delete all nodes, used when testing out the program to start fresh each time\n",
    "graph.delete_all()\n",
    "\n",
    "n_lines = 60511260\n",
    "approx_n_events = n_lines/9\n",
    "\n",
    "i = 0\n",
    "for event in generator:\n",
    "    #print('_______________________')\n",
    "    key = str(event.attrib['key'])\n",
    "    #print('Key: ' + key)\n",
    "    try:\n",
    "        xml = etree.tostring(event.find('title')).decode('utf-8') \n",
    "        title = re.search('<title>(.+?)</title>',xml).group(1)\n",
    "    except (AttributeError,TypeError):\n",
    "        continue\n",
    "    #print(title)\n",
    "    \n",
    "    university = 'None'\n",
    "    if (event.tag == 'phdthesis') or (event.tag == 'mastersthesis'):\n",
    "        try:\n",
    "            xml = etree.tostring(event.find('school')).decode('utf-8')\n",
    "            university = re.search('<school>(.+?)</school>',xml).group(1)\n",
    "            #print(school)\n",
    "        except (AttributeError,TypeError):\n",
    "            university = 'None'\n",
    "    \n",
    "    #save article node data\n",
    "    with open('./data/articles.csv','a') as csv_file:\n",
    "        line = key+','+title\n",
    "        csv_file.write(line)\n",
    "        csv_file.write('\\n')\n",
    "    \n",
    "    auth_list = event.findall('author')    \n",
    "    for author in auth_list:\n",
    "        try:\n",
    "            xml = etree.tostring(author).decode('utf-8')\n",
    "            name = re.search('<author>(.+?)</author>',xml).group(1)\n",
    "            #print(name)\n",
    "        except (AttributeError,TypeError):\n",
    "            continue\n",
    "         \n",
    "        #save author node data\n",
    "        with open('./data/authors.csv','a') as csv_file:\n",
    "            line = name+','+university\n",
    "            csv_file.write(line)\n",
    "            csv_file.write('\\n')\n",
    "        \n",
    "        #save relationship data\n",
    "        with open('./data/published.csv','a') as csv_file:\n",
    "            line = name+','+key\n",
    "            csv_file.write(line)\n",
    "            csv_file.write('\\n')\n",
    "\n",
    "        \n",
    "    i = i+1\n",
    "    if i%100000==0:\n",
    "        percent = (i/approx_n_events)*100\n",
    "        print('Extracting: '+str(percent)+'%')\n",
    "#    if i>30:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, copy the generated files to the neo4j folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.graph.Cursor at 0x7fb65ca92940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import articles\n",
    "graph.delete_all()\n",
    "graph.run('USING PERIODIC COMMIT 500 LOAD CSV WITH HEADERS FROM \"file:///articles.csv\" AS csvLine CREATE (a:Article {key: csvLine.key, title: csvLine.title})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run('USING PERIODIC COMMIT 500 LOAD CSV WITH HEADERS FROM \"file:///authors.csv\" AS csvLine MERGE (a:Author {name: csvLine.name})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.graph.Cursor at 0x7fb65ca4b780>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run('USING PERIODIC COMMIT 500 LOAD CSV WITH HEADERS FROM \"file:///published.csv\" AS csvLine MATCH (author:Author {name: csvLine.name}),(article:Article {key: csvLine.key}) CREATE (author)-[:PUBLISHED]->(article)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.graph.Cursor at 0x7fb65ca4b630>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forgot to add universities so had to add them like this\n",
    "graph.run('USING PERIODIC COMMIT 500 LOAD CSV WITH HEADERS FROM \"file:///authors.csv\" AS csvLine MATCH (a:Author {name: csvLine.name}) SET a.university = csvLine.university')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
